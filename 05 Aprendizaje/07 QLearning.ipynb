{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb633b29",
   "metadata": {},
   "source": [
    "# Q-learning en el ambiente del Frozen Lake\n",
    "\n",
    "<b>Autora</b>: Alicia Muñiz Jiménez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3b745",
   "metadata": {},
   "source": [
    "\n",
    "La clave para resolver problemas de aprendizaje por refuerzo (RL) es encontrar la política óptima ($\\pi^{*}$) de la función de valor para el problema específico. El Q-learning es un algoritmo del tipo modelo libre del RL basado en valor y es un policy off-learner, es decir, depende del ensayo y error para actualizar su experiencia y conocimiento del entorno, ya que tienen que aprender la dinámica del sistema a través de la experiencia, y aprende el valor de la política óptima independientemente del tipo de acciones del agente, así como que las actualizaciones de la función de valor se basan en la ecuación de Bellman  (Jang, Kim, Harerimana y Kim, 2019). \n",
    "\n",
    "\n",
    "Su Q proviene de quality (cualidad en inglés), ya que el Q-learning representa qué tan útil es una acción en ganar una recompensa a futuro (Shyalika, 2019). Es así que el Q-learning estima la función $Q(s,a)$ que es el valor esperado de hacer una acción 'a' en un estado 's' para estimar la política óptima y la ecuación de actualización de los valores $Q(s,a)$ es la siguiente: \n",
    "\n",
    "\n",
    "$$\n",
    "Q(s, a) = Q(s, a) + \\alpha [ r(s, a) + γmax Q' (s',a') - Q(s, a) ]\n",
    "$$\n",
    "\n",
    "\n",
    "Donde: \n",
    "\n",
    "*   $r(s,a)$ = recompensa obetenida en ese estado dada una acción.\n",
    "*   $γ$ = factor de descuento para el estado futuro (al que se transitará), su valor es fijo y puede tomar el rango de valores de [0,1].\n",
    "*   $α$ = parámetro de aprendizaje, no es fijo ya que al inicio comienza en 1 y con cada iteración irá disminuyendo su valor hasta alcanzar el valor de 0 o un límite inferior definido de antemano (ej. 0.01).\n",
    "*   $Q(s, a)$ = valor Q del estado actual dada la acción a.\n",
    "*   $max Q'(s', a')$ = máxima futura recompesa esperada del estado nuevo al que se transitará.\n",
    "\n",
    "\n",
    "Como se puede apreciar en la ecuación anterior, el Q-learning usa el método de diferencias temporales para la actualización o estimación de los valores Q, ya que sólo toma en cuenta el estado actual y el siguiente estado para estimar los valores Q (Matiisen, s. f.). Por otro lado, cuando el Q-learning es ejecutado se crea lo que se llama una tabla-Q, que es una matriz donde las filas normalmente representan cada estado posible y las columnas las acciones posibles en cada estado (Aggarwal, s.f. ). Por lo tanto, cada entrada de la matriz es un par estado-acción. La tabla siempre se inicializa con todos los valores en 0 y se actualiza cada entrada con la ecuación de actualización de los valores Q, de acuerdo con lo que el agente explora en cada iteración. La tabla al final sirve como referencia para que el agente pueda seleccionar la mejor acción basada en los valores Q.\n",
    "\n",
    "Finalmente, es importante recalcar que en el Q-learning el agente trabaja con una política epsilon-greedy, mas esta política no tiene valores fijos, sino que al inicio el algoritmo tiene un  epsilon de 1 y con cada iteración este valor va disminuyendo hasta terminar en 0 o en un límite inferior como 0.01, si es que así se especifica de antemano (Matiisen, s.f.). Esto se debe a que como el algoritmo no tiene conocimiento de la dinámica del sistema al inicio, entonces necesita explorar mucho para conocer el entorno, pero conforme va conociendo más del entorno puede explotar cada vez más y no solo explorar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e68fc5",
   "metadata": {},
   "source": [
    "Después de la breve introducción al Q-learning, ahora se procederá con un ejemplo práctico sobre dos agentes agentes que interactúan en el entorno virtual \"Frozen Lake\" del gimnasio OpenAI, esto para entender mejor el Q-learning y las diferencias que se pueden observar al compararlo con un agente que tiene una política de elección de comportamiento de acciones aleatorias. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ae6a6",
   "metadata": {},
   "source": [
    "## Explicación del ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e10ee",
   "metadata": {},
   "source": [
    "La documentación de la paquetería *gymnasium* describe las sigueintes características del ambiente *Frozen Lake* (Farama Foundation, 2023): \n",
    "\n",
    "* **Estado de acciones (4):**\n",
    "\n",
    "    - 0 = Izquierda\n",
    "    - 1 = Abajo\n",
    "    - 2 = Derecha\n",
    "    - 3 = Arriba\n",
    "    \n",
    "* **Espacio observacional (16):** Se utilizará el ambiente de Frozen Lake con una cuadrícula de tamaño 4x4, por lo que el total de observaciones posibles (estados) son 16. \n",
    "\n",
    "\n",
    "* **Recompenzas:**\n",
    "\n",
    "     - +1 si el agente alcanza la meta.\n",
    "     - 0 si el agente cae en alún hoyo en el hielo.\n",
    "     - 0 si el agente pasa por estados donde hay hielo congelado. \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9dc33",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d943b",
   "metadata": {},
   "source": [
    "**Instalación e importación de librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym \n",
    "import math, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf0e2f",
   "metadata": {},
   "source": [
    "# Agente con acciones aleatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff1a16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiente:\n",
      "[[b'S' b'H' b'F' b'F']\n",
      " [b'F' b'F' b'F' b'F']\n",
      " [b'F' b'F' b'F' b'H']\n",
      " [b'F' b'F' b'F' b'G']]\n",
      " Tamaño: 16; Núm. acciones: 4\n"
     ]
    }
   ],
   "source": [
    "#Crea ambiente; render_mode='human' permite visualizar gráficamente el entorno \n",
    "env=gym.make(\"FrozenLake-v1\",desc=[\"SHFF\", \"FFFF\", \"FFFH\", \"FFFG\"], is_slippery=False, render_mode=\"human\")\n",
    "#Índices de las acciones\n",
    "action_names = {0:'Izquierda', 1: 'Abajo', 2: 'Derecha', 3: 'Arriba'}\n",
    "\n",
    "#Número de acciones\n",
    "action_space_size = env.action_space.n\n",
    "#Número de cuadros\n",
    "state_space_size = env.observation_space.n\n",
    "\n",
    "print('Ambiente:\\n{}\\n Tamaño: {}; Núm. acciones: {}'.format(env.desc, state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9db83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensayo:1\n",
      "\tAcciones:['Izquierda', 'Derecha']; Recompensa: 0.0\n",
      "Ensayo:2\n",
      "\tAcciones:['Arriba', 'Arriba', 'Izquierda', 'Derecha']; Recompensa: 0.0\n",
      "Ensayo:3\n",
      "\tAcciones:['Abajo', 'Arriba', 'Arriba', 'Derecha']; Recompensa: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Número de ensayos\n",
    "ensayos = 3\n",
    "for ensayos in range(1, ensayos+1):\n",
    "    #Estado inicial\n",
    "    estado = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    actions = []\n",
    "    while not done:\n",
    "        #Visualiza el ambiente\n",
    "        #env.render() #Quitar comentario para visualizar\n",
    "        #Muestrea una acción\n",
    "        action = env.action_space.sample()\n",
    "        actions.append(action_names[action])\n",
    "        #Obtiene la recompensa por la acción\n",
    "        _, reward, done, _, _ = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print('Ensayo:{}\\n\\tAcciones:{}; Recompensa: {}'.format(ensayos, actions, score))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f975a90",
   "metadata": {},
   "source": [
    "Un ejemplo de la exploración que hace el agente se puede visualizar de la siguiente forma:\n",
    "\n",
    "![image](Images/FrozenLake.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0544e",
   "metadata": {},
   "source": [
    "## Agente con el algorito de Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ecb236",
   "metadata": {},
   "source": [
    "Se usó como base el código de Brooker (2020) sobre su agente de Q-learning en el ambiente de CartPole-v1, pero se adaptó para el ambiente Frozen Lake y el tipo de variables que maneja este ambiente. Además se implementaron cambios respecto al ambiente original, para fines didácticos y cambios en el código para adaptarlo a las nuevas actualizaciones de la paquetería gymnasium. De igual forma, se agregó una etapa de prueba al final para comprobar qué tan bien aprendió el agente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd18478",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\"FrozenLake-v1\",desc=[\"SFFF\", \"FHFF\", \"FFFH\", \"FFFG\"], is_slippery=False, render_mode=\"ansi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04289d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Izquierda</th>\n",
       "      <th>Abajo</th>\n",
       "      <th>Derecha</th>\n",
       "      <th>Arriba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Izquierda  Abajo  Derecha  Arriba\n",
       "0         0.0    0.0      0.0     0.0\n",
       "1         0.0    0.0      0.0     0.0\n",
       "2         0.0    0.0      0.0     0.0\n",
       "3         0.0    0.0      0.0     0.0\n",
       "4         0.0    0.0      0.0     0.0\n",
       "5         0.0    0.0      0.0     0.0\n",
       "6         0.0    0.0      0.0     0.0\n",
       "7         0.0    0.0      0.0     0.0\n",
       "8         0.0    0.0      0.0     0.0\n",
       "9         0.0    0.0      0.0     0.0\n",
       "10        0.0    0.0      0.0     0.0\n",
       "11        0.0    0.0      0.0     0.0\n",
       "12        0.0    0.0      0.0     0.0\n",
       "13        0.0    0.0      0.0     0.0\n",
       "14        0.0    0.0      0.0     0.0\n",
       "15        0.0    0.0      0.0     0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabla de valores Q inicalmente con 0s\n",
    "Q_table= np.zeros((state_space_size, action_space_size))\n",
    "pd.DataFrame(data=Q_table, columns=['Izquierda', 'Abajo', 'Derecha', 'Arriba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc266f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, Q_table):\n",
    "    \"\"\"Elije la acción en base a una política ambiciosa\"\"\"\n",
    "    return np.argmax(Q_table[state])\n",
    "\n",
    "def new_Q_value( reward, new_state, Q_table, discount_factor=1 ):\n",
    "    \"\"\"Diferencia temporta para acutaliza el valor-Q del par estado-acción\"\"\"\n",
    "    #obtiene Q*\n",
    "    future_optimal_value = np.max(Q_table[new_state])\n",
    "    #R + \\gammaxQ*\n",
    "    learned_value = reward + discount_factor * future_optimal_value\n",
    "    \n",
    "    return learned_value\n",
    "\n",
    "def learning_rate(n, min_rate=0.01 ):\n",
    "    \"\"\"Apata la tasa de aprendizaje\"\"\"\n",
    "    return max(min_rate, min(1.0, 1.0 - math.log10((n + 1) / 25)))\n",
    "\n",
    "def exploration_rate(n, min_rate= 0.1 ):\n",
    "    \"\"\"Adapta la tasa de exploración\"\"\"\n",
    "    return max(min_rate, min(1, 1.0 - math.log10((n  + 1) / 25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290b6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\n",
      "\tPuntaje:0.0; Acciones:['Derecha', 'Abajo']\n"
     ]
    }
   ],
   "source": [
    "puntajes_ep = []\n",
    "#Número de episodios\n",
    "n_episodes = 100\n",
    "for e in range(1, n_episodes+1):\n",
    "    #Estado inicial\n",
    "    current_state = env.reset()[0]\n",
    "    done = False\n",
    "    score = 0\n",
    "    actions = []\n",
    "    while done==False:\n",
    "        #Escoje acción de acuerdo con la política\n",
    "        action = policy(current_state, Q_table)\n",
    "        \n",
    "        #Genera núm. aleatorio, si es menor al rango de exploración\n",
    "        #realiza una acción aleatoria\n",
    "        if np.random.random() < exploration_rate(e) : \n",
    "            action = env.action_space.sample()\n",
    "        actions.append(action_names[action])\n",
    "         \n",
    "        #Cálcula la recompensa y actualiza las observaciones\n",
    "        obs, reward, done, _, _ = env.step(action)\n",
    "        new_state = obs\n",
    "        score += reward\n",
    "\n",
    "        #Rango de aprendizaje\n",
    "        lr = learning_rate(e)\n",
    "        #Actualiza la tabla para valores Q\n",
    "        learnt_value = new_Q_value(reward, new_state, Q_table )\n",
    "        old_value = Q_table[current_state, action]\n",
    "        #Cálcula el nuevo valor Q: (1-l)*Q_t + l*Q_t+1\n",
    "        Q_table[current_state, action] = (1-lr)*old_value + lr*learnt_value\n",
    "        #Cambia al nuevo estado\n",
    "        current_state = new_state\n",
    "    puntajes_ep.append(score)\n",
    "    if e % 100 == 0:\n",
    "        print('Episode {}\\n\\tPuntaje:{}; Acciones:{}'.format(e, score, actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b135a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(puntajes_ep,'o')\n",
    "plt.title('Scores en cada episodio')\n",
    "plt.xlabel('Episodio')\n",
    "plt.ylabel('Recompensa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56646c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Izquierda</th>\n",
       "      <th>Abajo</th>\n",
       "      <th>Derecha</th>\n",
       "      <th>Arriba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.995040</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.997014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.985112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.978925</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.954103</td>\n",
       "      <td>0.995505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998937</td>\n",
       "      <td>0.122738</td>\n",
       "      <td>0.852224</td>\n",
       "      <td>0.690136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.428628</td>\n",
       "      <td>0.903808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.930017</td>\n",
       "      <td>0.964474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.411164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391208</td>\n",
       "      <td>0.996588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.916456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709178</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.867545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Izquierda     Abajo   Derecha    Arriba\n",
       "0    0.982011  0.995040  0.999982  0.997014\n",
       "1    0.995936  0.000000  0.999988  0.985112\n",
       "2    0.978925  0.999991  0.954103  0.995505\n",
       "3    0.998937  0.122738  0.852224  0.690136\n",
       "4    0.428628  0.903808  0.000000  0.999740\n",
       "5    0.000000  0.000000  0.000000  0.000000\n",
       "6    0.000000  0.999992  0.930017  0.964474\n",
       "7    0.411164  0.000000  0.000000  0.968456\n",
       "8    0.000000  0.000000  0.391208  0.996588\n",
       "9    0.916456  0.000000  0.000000  0.000000\n",
       "10   0.536965  0.999995  0.000000  0.988984\n",
       "11   0.000000  0.000000  0.000000  0.000000\n",
       "12   0.000000  0.000000  0.000000  0.369315\n",
       "13   0.000000  0.000000  0.000000  0.000000\n",
       "14   0.000000  0.709178  0.999999  0.867545\n",
       "15   0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=Q_table, columns=['Izquierda', 'Abajo', 'Derecha', 'Arriba'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac53d8e",
   "metadata": {},
   "source": [
    "## Prueba de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076109fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\"FrozenLake-v1\",desc=[\"SFFF\", \"FHFF\", \"FFFH\", \"FFFG\"], is_slippery=False, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d355f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio: 1\n",
      "\tAcciones: ['Derecha', 'Abajo', 'Derecha', 'Derecha', 'Abajo', 'Abajo', 'Abajo', 'Derecha']; Puntaje: 1.0\n",
      "Episodio: 2\n",
      "\tAcciones: ['Derecha', 'Abajo', 'Derecha', 'Derecha', 'Abajo', 'Abajo', 'Abajo', 'Derecha', 'Derecha', 'Derecha', 'Abajo', 'Abajo', 'Abajo', 'Derecha']; Puntaje: 1.0\n",
      "Episodio: 3\n",
      "\tAcciones: ['Derecha', 'Abajo', 'Derecha', 'Derecha', 'Abajo', 'Abajo', 'Abajo', 'Derecha', 'Derecha', 'Derecha', 'Abajo', 'Abajo', 'Abajo', 'Derecha', 'Derecha', 'Derecha', 'Abajo', 'Abajo', 'Abajo', 'Derecha']; Puntaje: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_episodes_t = 3\n",
    "for e in range(1, n_episodes_t+1):\n",
    "    #Estado inicial\n",
    "    current_state = env.reset()[0]\n",
    "    done = False\n",
    "    score = 0\n",
    "    actions\n",
    "    while done==False:\n",
    "        #Elije acción de acuerdo a política \n",
    "        action = policy(current_state, Q_table)\n",
    "        actions.append(action_names[action])\n",
    "        #Actúa en el ambiente y cálcula recompensa\n",
    "        obs, reward, done, _,_= env.step(action)\n",
    "        new_state = obs        \n",
    "        score += reward\n",
    "        #Actualiza el estado\n",
    "        current_state = new_state\n",
    "\n",
    "\n",
    "    print('Episodio: {}\\n\\tAcciones: {}; Puntaje: {}'.format(e, actions, score))\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd4172",
   "metadata": {},
   "source": [
    "![image](Images/SolFrozenLake.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94514a2a",
   "metadata": {},
   "source": [
    "**Referencias:** \n",
    "\n",
    "* Aggarwal, R. (s. f.). Q-learning - Reinforcement Learning. Recuperado el 15 de diciembre de 2022. https://miet.ac.in/assets/uploads/cs/Q%20Learning.pdf\n",
    "\n",
    "* Brooker, R. (2020). OpenAI Gym: CartPole-v1 - Q-Learning [Youtube]. https://www.youtube.com/watch?v=JNKvJEzuNsc&t=227s\n",
    "\n",
    "* Jang, B. Kim, M. Harerimana, G. y Kim, J.W. (2019). \"Q-Learning Algorithms: A Comprehensive Classification and Applications,\". IEEE Access, vol. 7,133653-133667, doi: 10.1109/ACCESS.2019.2941229\n",
    "\n",
    "* Matiisen, T. (s. f.). Q-learning [Presentación]. Recuperado el 15 de diciembre de 2022. https://courses.cs.ut.ee/MTAT.03.292/2014_spring/uploads/Main/Q-learning.pdf\n",
    "\n",
    "* Farama Foundation. (2023). Frozen Lake. Gymnasium Documentation. Recuperado el 28 de marzo de 2023. https://gymnasium.farama.org/environments/toy_text/frozen_lake/\n",
    "\n",
    "* Shyalika, C. (2019). A Beginners Guide to Q-Learning. En Towards Data Science. Recuperado el 8 de diciembre de 2022. https://towardsdatascience.com/a-beginners-guide-to-q-learning-c3e2a30a653c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
